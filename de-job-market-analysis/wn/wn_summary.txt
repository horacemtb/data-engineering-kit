Basic Qualifications: 5+ years experience in data engineering with expertise in data architecture and pipelines Strong programming skills in Python and proficient with relational databases, data modeling, and SQL Experience with big data technologies (eg: Hive, Spark, Presto) Familiarity with batch and streaming architectures preferred Knowledgeable on data governance and compliance best practices Ability to communicate technical concepts clearly and concisely and independence and passion for innovation and learning new technologies Preferred Qualifications: Hands-on experience with some of: AWS, Databricks, Delta Lake, Airflow, DBT, Redshift, Datahub, Elementary If this opportunity interests you, you might like these courses on Coursera: Big Data Specialization Data Warehousing for Business Intelligence IBM Data Engineering Professional Certificate #LI-JP2 Apply for this position Bookmark Report About the job Full-time Canada 17 Applicants Posted 2 weeks ago python big data sql aws machine learning Apply for this position Bookmark Report Senior Data Engineer Coursera Job Overview: Does architecting high quality and scalable data pipelines powering business critical applications excite you? Basic Qualifications: 5+ years experience in data engineering with expertise in data architecture and pipelines Strong programming skills in Python and proficient with relational databases, data modeling, and SQL Experience with big data technologies (eg: Hive, Spark, Presto) Familiarity with batch and streaming architectures preferred Knowledgeable on data governance and compliance best practices Ability to communicate technical concepts clearly and concisely and independence and passion for innovation and learning new technologies Preferred Qualifications: Hands-on experience with some of: AWS, Databricks, Delta Lake, Airflow, DBT, Redshift, Datahub, Elementary If this opportunity interests you, you might like these courses on Coursera: Big Data Specialization Data Warehousing for Business Intelligence IBM Data Engineering Professional Certificate #LI-JP2 Data Engineering plays a crucial role in building a robust and reliable data infrastructure that enables data-driven decision-making, as well as various data analytics and machine learning initiatives within Coursera. This is the role for you, if you’re excited to work on the things listed below: Build and maintain end-to-end data pipelines Design and build components within data pipelines for collecting production data Data engineering for efficient ingestion of data Helping the team build and maintain analytics and insights infrastructure Monitoring the production and setting up alerting mechanisms The skills you will need to be successful in the above: 7+ years of software engineering experience, notable part of it being in the data engineering space Expertise with designing and building data pipelines within the ETL and ELT paradigm Expertise in distributed systems, as well as different database systems and big data solutions Previous experience in designing, building and maintaining cloud infrastructure to support analytics operations Experience with working in Python, Spark and SQL Experience with some of the following tools: dbt, Airflow, Kafka, AWS Glue, delta lake Excellent problem-solving skills and ability to think critically Desire to work in a fast-paced, collaborative environment Excellent communication skills, both verbal and written Even if you don’t meet all the criteria listed above, we would still love to hear from you! This is the role for you, if you’re excited to work on the things listed below: Build and maintain end-to-end data pipelines Design and build components within data pipelines for collecting production data Data engineering for efficient ingestion of data Helping the team build and maintain analytics and insights infrastructure Monitoring the production and setting up alerting mechanisms The skills you will need to be successful in the above: 7+ years of software engineering experience, notable part of it being in the data engineering space Expertise with designing and building data pipelines within the ETL and ELT paradigm Expertise in distributed systems, as well as different database systems and big data solutions Previous experience in designing, building and maintaining cloud infrastructure to support analytics operations Experience with working in Python, Spark and SQL Experience with some of the following tools: dbt, Airflow, Kafka, AWS Glue, delta lake Excellent problem-solving skills and ability to think critically Desire to work in a fast-paced, collaborative environment Excellent communication skills, both verbal and written Even if you don’t meet all the criteria listed above, we would still love to hear from you! Including but not limited to: Building and designing Data Lake, Data Warehouse and Data Mart solutions Database design and data modeling experience including performance optimization Experience working in report development tools like tableau, powerBI Experience working in a variety of data stores (sql and no-sql) and file formats.