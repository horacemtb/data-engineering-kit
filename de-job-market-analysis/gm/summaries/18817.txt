Технологии/инструменты Spark/Scala Hadoop Hive SQL Что предстоит делать Разрабатывать процессы сборки, обработки и поставки данных в Hadoop на Spark. Ожидания Опыт разработки на Spark (желательно Spark/Scala). Наша задача — обеспечить перевод Legacy процессов на современный стек технологий, разработать решения по обработке и доставке данных, создать с 0 процессы загрузки потоков данных для задач аналитики и развить MLOps практику в команде для вывода DS моделей в пром.